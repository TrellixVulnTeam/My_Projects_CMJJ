{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lyceum/rr2n17/.conda/envs/rrkeras/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import codecs\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sents = (open('IITB.en-hi.en', encoding='utf-8', errors='ignore').read()).split(\"\\n\")[:-1]\n",
    "hi_sents = (open('IITB.en-hi.hi', encoding='utf-8', errors='ignore').read()).split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग - इन खाका</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग - इन खाका</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "      <td>उन प्लग - इनों की सूची जिन्हें डिफोल्ट रूप से ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              eng  \\\n",
       "0  Give your application an accessibility workout   \n",
       "1               Accerciser Accessibility Explorer   \n",
       "2  The default plugin layout for the bottom panel   \n",
       "3     The default plugin layout for the top panel   \n",
       "4  A list of plugins that are disabled by default   \n",
       "\n",
       "                                                 ger  \n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें  \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक  \n",
       "2            निचले पटल के लिए डिफोल्ट प्लग - इन खाका  \n",
       "3             ऊपरी पटल के लिए डिफोल्ट प्लग - इन खाका  \n",
       "4  उन प्लग - इनों की सूची जिन्हें डिफोल्ट रूप से ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.DataFrame(columns=['eng', 'hindi'])\n",
    "lines.eng = eng_sents\n",
    "lines.hindi = hi_sents\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1492827, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_clean = []\n",
    "for line in lines.hindi:\n",
    "    nstr = re.sub('\\s+_\\s+[A-Za-z]','',line)\n",
    "    nstr = re.sub('\\(*\\)*','',nstr)\n",
    "    nstr = re.sub('%.*?[A-Za-z]','',nstr)\n",
    "    nstr = re.sub('[A-Za-z]','',nstr)\n",
    "    nstr = nstr.strip()\n",
    "    nstr = re.sub('\\s+',' ',nstr)\n",
    "    #line = nstr\n",
    "    hindi_clean.append(nstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_clean = []\n",
    "for line in lines.eng:\n",
    "    estr = re.sub('\\s+_\\s','',line)\n",
    "    estr = re.sub(r'[^\\x00-\\x7F]+',' ', estr)\n",
    "    estr = estr.strip()\n",
    "    estr = re.sub('\\s+',' ',estr)\n",
    "    eng_clean.append(estr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1000000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi_clean), len(eng_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.hindi = hindi_clean\n",
    "lines.eng = eng_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.hindi=lines.hindi.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.hindi=lines.hindi.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.hindi=lines.hindi.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>566435</th>\n",
       "      <td>ok  got it</td>\n",
       "      <td>ठीक है  समझ गए</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124447</th>\n",
       "      <td>issued by organization</td>\n",
       "      <td>संगठन द्वारा जारी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516222</th>\n",
       "      <td>besides the astonishing conceit of these olymp...</td>\n",
       "      <td>इन चौंकाने वाली घोषणाओं के बाद भी किसी को आश्च...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232402</th>\n",
       "      <td>user name   if necessary</td>\n",
       "      <td>उपयोक्ता नामः यदि आवश्यक हो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93951</th>\n",
       "      <td>new test</td>\n",
       "      <td>नया परीक्षण</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114379</th>\n",
       "      <td>send reply to all recipients</td>\n",
       "      <td>प्रेषक या प्राप्तकर्ता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911901</th>\n",
       "      <td>emboss</td>\n",
       "      <td>उभार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576335</th>\n",
       "      <td>show date in clock</td>\n",
       "      <td>घड़ी में तिथि दिखाएँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854439</th>\n",
       "      <td>siamese</td>\n",
       "      <td>सायमीस</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746655</th>\n",
       "      <td>progressive</td>\n",
       "      <td>उन्नतशील</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "566435                                        ok  got it    \n",
       "124447                             issued by organization   \n",
       "516222  besides the astonishing conceit of these olymp...   \n",
       "232402                          user name   if necessary    \n",
       "93951                                            new test   \n",
       "114379                      send reply to all recipients    \n",
       "911901                                             emboss   \n",
       "576335                                 show date in clock   \n",
       "854439                                            siamese   \n",
       "746655                                        progressive   \n",
       "\n",
       "                                                      ger  \n",
       "566435                                     ठीक है  समझ गए  \n",
       "124447                                  संगठन द्वारा जारी  \n",
       "516222  इन चौंकाने वाली घोषणाओं के बाद भी किसी को आश्च...  \n",
       "232402                        उपयोक्ता नामः यदि आवश्यक हो  \n",
       "93951                                         नया परीक्षण  \n",
       "114379                             प्रेषक या प्राप्तकर्ता  \n",
       "911901                                               उभार  \n",
       "576335                               घड़ी में तिथि दिखाएँ  \n",
       "854439                                             सायमीस  \n",
       "746655                                           उन्नतशील  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter short sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSent = pd.DataFrame(columns=['eng', 'hindi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "englist = []\n",
    "hindilist = []\n",
    "for index, row in lines.iterrows():\n",
    "    #print (row['eng'], row['ger'])\n",
    "    eng1 = row['eng']\n",
    "    eng1 = eng1.strip()\n",
    "    eng1 = re.sub('\\s+',' ',eng1)\n",
    "    hindi1 = row['hindi']\n",
    "    hindi1 = hindi1.strip()\n",
    "    hindi1 = re.sub('\\s+',' ',hindi1)\n",
    "    ctr1 = 0\n",
    "    ctr2 = 0\n",
    "    HinWords = hindi1.split(' ')\n",
    "    for wrd in HinWords:\n",
    "        newWrd1 = wrd.strip()\n",
    "        if len(newWrd1) > 0:\n",
    "            ctr1 = ctr1 + 1\n",
    "    EngWords = eng1.split(' ')\n",
    "    for wrd in EngWords:\n",
    "        newWrd2 = wrd.strip()\n",
    "        if len(newWrd2) > 0:\n",
    "            ctr2 = ctr2 + 1\n",
    "    if ctr1 <= 30 and ctr2 <= 30:\n",
    "        englist.append(eng1)\n",
    "        hindilist.append(hindi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889523, 889523)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(englist), len(hindilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSent.eng = englist\n",
    "shortSent.hindi = hindilist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889523, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortSent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407161</th>\n",
       "      <td>they had the spirit of adventure in them and l...</td>\n",
       "      <td>उनमें साहस होता था उनके लिए जिंदगी एक मनोरंजक ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395726</th>\n",
       "      <td>ya muhammad</td>\n",
       "      <td>या मुहम्मद</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726365</th>\n",
       "      <td>frantic</td>\n",
       "      <td>उन्मत्त</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690682</th>\n",
       "      <td>fiend</td>\n",
       "      <td>दैत्य</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684020</th>\n",
       "      <td>audacity</td>\n",
       "      <td>ढिठाई</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "407161  they had the spirit of adventure in them and l...   \n",
       "395726                                        ya muhammad   \n",
       "726365                                            frantic   \n",
       "690682                                              fiend   \n",
       "684020                                           audacity   \n",
       "\n",
       "                                                    hindi  \n",
       "407161  उनमें साहस होता था उनके लिए जिंदगी एक मनोरंजक ...  \n",
       "395726                                         या मुहम्मद  \n",
       "726365                                            उन्मत्त  \n",
       "690682                                              दैत्य  \n",
       "684020                                              ढिठाई  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortSent.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSent.eng = shortSent.eng.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484310</th>\n",
       "      <td>START_ south khorasan province _END</td>\n",
       "      <td>दक्षिण ख़ोरासान प्रांत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105102</th>\n",
       "      <td>START_ show timezone field in the event meetin...</td>\n",
       "      <td>घटना बैठक संपादक में समयक्षेत्र क्षेत्र दिखायें</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472184</th>\n",
       "      <td>START_ after all how could the world exist wit...</td>\n",
       "      <td>इन सब के बाद भी यदि भगवान् करुणामय ना हो तो इस...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704628</th>\n",
       "      <td>START_ vituperation _END</td>\n",
       "      <td>शाबर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252942</th>\n",
       "      <td>START_ and o dear prophet mohammed peace and b...</td>\n",
       "      <td>और ऐ रसूल तुम कह दो परवरदिगार तू मेरी उम्मत को...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "484310                START_ south khorasan province _END   \n",
       "105102  START_ show timezone field in the event meetin...   \n",
       "472184  START_ after all how could the world exist wit...   \n",
       "704628                           START_ vituperation _END   \n",
       "252942  START_ and o dear prophet mohammed peace and b...   \n",
       "\n",
       "                                                    hindi  \n",
       "484310                             दक्षिण ख़ोरासान प्रांत  \n",
       "105102    घटना बैठक संपादक में समयक्षेत्र क्षेत्र दिखायें  \n",
       "472184  इन सब के बाद भी यदि भगवान् करुणामय ना हो तो इस...  \n",
       "704628                                               शाबर  \n",
       "252942  और ऐ रसूल तुम कह दो परवरदिगार तू मेरी उम्मत को...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortSent.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in shortSent.eng:\n",
    "    for word in eng.split(' '):\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "    \n",
    "all_hindi_words=set()\n",
    "for hindi in shortSent.hindi:\n",
    "    for word in hindi.split(' '):\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109090, 158389)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words), len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list=[]\n",
    "for l in shortSent.hindi:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "np.max(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list=[]\n",
    "for l in shortSent.eng:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "np.max(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_hindi_words))\n",
    "target_words = sorted(list(all_eng_words))\n",
    "num_encoder_tokens = len(all_hindi_words)\n",
    "num_decoder_tokens = len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889523, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortSent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shortSent[:800000]\n",
    "test = shortSent[800000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89523, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Encoder-Decoder\n",
    "encoder_input_data_train = np.zeros(\n",
    "    (len(train), 30),\n",
    "    dtype='float32')\n",
    "decoder_input_data_train = np.zeros(\n",
    "    (len(train), 32),\n",
    "    dtype='float32')\n",
    "decoder_target_data_train = np.zeros(\n",
    "    (len(train), 32, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Encoder-Decoder\n",
    "encoder_input_data_test = np.zeros(\n",
    "    (len(test), 30),\n",
    "    dtype='float32')\n",
    "decoder_input_data_test = np.zeros(\n",
    "    (len(test), 32),\n",
    "    dtype='float32')\n",
    "decoder_target_data_test = np.zeros(\n",
    "    (len(test), 32, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(train.hindi, train.eng)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data_train[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_train[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data_train[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(test.hindi, test.eng)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data_test[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_test[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data_test[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "en_x =  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
    "\n",
    "encoder = LSTM(50, return_state=True, go_backwards=True)\n",
    "#encoder = LSTM(100, return_state=True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the decoder, using `encoder_states` as initial state.\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "dex =  Embedding(num_decoder_tokens, embedding_size)\n",
    "\n",
    "final_dex = dex(decoder_inputs)\n",
    "\n",
    "\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "#decoder_lstm = LSTM(100, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     7919450     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     5454500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50), (None,  20200       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 50), ( 20200       embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 109090) 5563590     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 18,977,940\n",
      "Trainable params: 18,977,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_1M.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_1M.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x2ab9ff2f3da0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x2ab9ff2f35c0>,\n",
       " <keras.layers.embeddings.Embedding at 0x2ab9ff2f3a58>,\n",
       " <keras.layers.embeddings.Embedding at 0x2ab9ff2f3cf8>,\n",
       " <keras.layers.recurrent.LSTM at 0x2ab9ff32d2e8>,\n",
       " <keras.layers.recurrent.LSTM at 0x2ab9ff32d6d8>,\n",
       " <keras.layers.core.Dense at 0x2ab9ff32d898>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 50)          7919450   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 7,939,650\n",
      "Trainable params: 7,939,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From previously trained model\n",
    "encoder_inputs = model.layers[0].input\n",
    "encoder_outputs, state_h, state_c = model.layers[4].output\n",
    "encoder_states = [state_h, state_c]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = model.layers[1].input #input_2\n",
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "dec_emb = model.layers[3]\n",
    "final_dex2 = dec_emb(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent.LSTM at 0x2ab9ff32d6d8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(50)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dex2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(50)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_state_input_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(50)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_state_input_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = model.layers[5]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h_dec, state_c_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = model.layers[-1]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(109090)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None)])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(50)])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_h_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beam Search\n",
    "def beam_search_test(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    # walk over each step in sequence\n",
    "    #for row in data:\n",
    "    all_candidates = list()\n",
    "    # expand each current candidate\n",
    "    for i in range(len(sequences)):\n",
    "        seq, score = sequences[i]\n",
    "        for j in range(len(data)):\n",
    "            candidate = [seq + [j], score * - np.log(data[j])]\n",
    "            all_candidates.append(candidate)\n",
    "    # order all candidates by score\n",
    "    ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "    # select k best\n",
    "    sequences = np.array(ordered[:k])\n",
    "    word1 = reverse_target_char_index[sequences[0,0][0]]\n",
    "    word2 = reverse_target_char_index[sequences[1,0][0]]\n",
    "    prob1 = data[sequences[0,0][0]]\n",
    "    prob2 = data[sequences[1,0][0]]\n",
    "#     print('Words: ', word1, word2)\n",
    "#     print('Prob: ', prob1, prob2)\n",
    "    return [(word1, prob1, sequences[0,0][0]) , (word2, prob2, sequences[1,0][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode with Beam Search\n",
    "def decode_sequence_test(states_value, target_seq, decoded_sentence, decoded_sentence_list, stop_condition, current_sent_prob):   \n",
    "    if stop_condition == True:\n",
    "        decoded_sentence_list.append((decoded_sentence, current_sent_prob))\n",
    "        return\n",
    "    #Else\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)  \n",
    "    #print('output tokens shape: ', output_tokens.shape)\n",
    "    sampled_tokens = beam_search_test(output_tokens[0, -1, :], 2)\n",
    "    sampled_charA = sampled_tokens[0][0]\n",
    "    sampled_charB = sampled_tokens[1][0]\n",
    "    \n",
    "    probA = sampled_tokens[0][1]\n",
    "    probB = sampled_tokens[1][1]\n",
    "    \n",
    "    sampled_token_indexA = sampled_tokens[0][2]\n",
    "    sampled_token_indexB = sampled_tokens[1][2]\n",
    "    \n",
    "#     print('Words: ', sampled_charA, sampled_charB)\n",
    "#     print('Probabilities: ', probA, probB)\n",
    "\n",
    "    if (sampled_charA == '_END' or len(decoded_sentence) > 52):\n",
    "        #print('Decoded sentence after Beam: ', decoded_sentence)\n",
    "        return decode_sequence_test(states_value, target_seq, decoded_sentence, decoded_sentence_list, True, current_sent_prob)\n",
    "    if (sampled_charB == '_END' or len(decoded_sentence) > 52):\n",
    "        #print('Decoded sentence after Beam: ', decoded_sentence)\n",
    "        return decode_sequence_test(states_value, target_seq, decoded_sentence, decoded_sentence_list, True, current_sent_prob)\n",
    "    decoded_sentenceA = decoded_sentence+' '+sampled_charA\n",
    "    decoded_sentenceB = decoded_sentence+' '+sampled_charB\n",
    "    target_seqA = np.zeros((1,1))\n",
    "    target_seqB = np.zeros((1,1))\n",
    "    target_seqA[0, 0] = sampled_token_indexA\n",
    "    target_seqB[0, 0] = sampled_token_indexB\n",
    "    # Update states\n",
    "    states_value = [h, c]\n",
    "    decode_sequence_test(states_value, target_seqA, decoded_sentenceA, decoded_sentence_list, stop_condition, current_sent_prob * probA)\n",
    "    decode_sequence_test(states_value, target_seqB, decoded_sentenceB, decoded_sentence_list, stop_condition, current_sent_prob * probB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq_array):\n",
    "    \n",
    "    decoded_sentence_list = []\n",
    "    for input_seq in input_seq_array:\n",
    "        # Encode the input as state vectors.\n",
    "        #print('Input seq inside function: ', input_seq)\n",
    "        states_value = encoder_model.predict(input_seq)\n",
    "        #print('Encoder State values: ', states_value)\n",
    "        # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1,1))\n",
    "        # Populate the first character of target sequence with the start character.\n",
    "        target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "        # Sampling loop for a batch of sequences\n",
    "        # (to simplify, here we assume a batch of size 1).\n",
    "        stop_condition = False\n",
    "        decoded_sentence = ''\n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = decoder_model.predict(\n",
    "                [target_seq] + states_value)\n",
    "#             print('Decoder Output Token: ', output_tokens)\n",
    "#             print('Decoder Hidden State: ', h)\n",
    "#             print('Decoder Cell State: ', c)\n",
    "            # Sample a token\n",
    "            #result = beam_search_decoder(data, 3)\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "            decoded_sentence += ' '+sampled_char\n",
    "\n",
    "            # Exit condition: either hit max length\n",
    "            # or find stop character.\n",
    "            if (sampled_char == '_END' or\n",
    "               len(decoded_sentence) > 52):\n",
    "                stop_condition = True\n",
    "\n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1,1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "        decoded_sentence_list.append(decoded_sentence)\n",
    "\n",
    "    return decoded_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predictions\n",
      "***************\n",
      "*********Source************\n",
      " [5    अवधि को हाइलाइट रकें\n",
      "Name: hindi, dtype: object]\n",
      "*********Target************\n",
      " ['START_ highlight duration _END']\n",
      "*********Decoded sentence without Beam Search***********\n",
      " [' highlight duration _END']\n",
      "*********Decoded sentence with Beam Search***********\n",
      " [(' highlight duration', 0.7293454149614718), (' duration highlight', 0.008283969517888512)]\n"
     ]
    }
   ],
   "source": [
    "#Training predictions\n",
    "input_sent_list = list()\n",
    "source_sent_list = list()\n",
    "target_sent_list = list()\n",
    "print('Starting predictions')\n",
    "for seq_index in [5]:\n",
    "    input_sent = encoder_input_data_train[seq_index: seq_index + 1]\n",
    "#     print(\"Input seq type: \", type(input_sent))\n",
    "#     print('Input seq: ', input_sent)\n",
    "    input_sent_list.append(input_sent)\n",
    "    target_sent_list.append(train.eng[seq_index])\n",
    "    source_sent_list.append(train.hindi[seq_index: seq_index + 1])\n",
    "    decoded_sentence_list_without_beam = decode_sequence(input_sent_list)\n",
    "    #Beam serach\n",
    "    decoded_sentence_list = []\n",
    "    states_value = encoder_model.predict(input_sent)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    current_sent_prob = 1.0\n",
    "    decode_sequence_test(states_value, target_seq, decoded_sentence, decoded_sentence_list, stop_condition, current_sent_prob)\n",
    "    print('***************')\n",
    "    print('*********Source************\\n', source_sent_list)\n",
    "    print('*********Target************\\n', target_sent_list)\n",
    "    print('*********Decoded sentence without Beam Search***********\\n', decoded_sentence_list_without_beam)\n",
    "    sortedSent = sorted(decoded_sentence_list, key=lambda kv: kv[1], reverse=True)\n",
    "    print('*********Decoded sentence with Beam Search***********\\n', sortedSent[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines.iloc[142930]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(input_sentence):\n",
    "    input_sent = []\n",
    "    for word in input_sentence.split(' '):\n",
    "        input_sent.append(word)\n",
    "    index_array = np.zeros((1, 30), dtype='float32')\n",
    "    index = 0\n",
    "    for item in input_sent:\n",
    "        if item not in input_token_index:\n",
    "            index_array[0, index] = 0.\n",
    "        else:\n",
    "            index_array[0, index] = input_token_index[item]\n",
    "        index = index + 1\n",
    "    return index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predictions\n",
      "Encoded sent details:  (1, 30) <class 'numpy.ndarray'>\n",
      "*********Source************\n",
      " चुनें नेता परियोजना से पुस्तिका पता अपनी\n",
      "*********Decoded sentence with Beam Search***********\n",
      " [(' select the book from a book', 6.2193361616012e-05), (' select the name of data book', 5.106501278220716e-05), (' select the name of the data book', 4.4346855984190225e-05), (' bookmark for this book exists', 2.622190833896465e-05), (' select an a book from the name', 1.7014914158077026e-05)]\n"
     ]
    }
   ],
   "source": [
    "# #Training predictions\n",
    "# input_sent_list = list()\n",
    "# source_sent_list = list()\n",
    "# target_sent_list = list()\n",
    "# print('Starting predictions')\n",
    "# input_from_user = 'चुनें नेता परियोजना से पुस्तिका पता अपनी'    ##Reversed sentence\n",
    "# encoded_sent = tokenize_input(input_from_user)\n",
    "# print('Encoded sent details: ', encoded_sent.shape, type(encoded_sent))\n",
    "# #print('Encoded sent: ',encoded_sent)\n",
    "\n",
    "# #Beam serach\n",
    "# decoded_sentence_list = []\n",
    "# states_value = encoder_model.predict(encoded_sent)\n",
    "# target_seq = np.zeros((1,1))\n",
    "# # Populate the first character of target sequence with the start character.\n",
    "# target_seq[0, 0] = target_token_index['START_']\n",
    "# stop_condition = False\n",
    "# decoded_sentence = ''\n",
    "# current_sent_prob = 1.0\n",
    "# decode_sequence_test(states_value, target_seq, decoded_sentence, decoded_sentence_list, stop_condition, current_sent_prob)\n",
    "# print('*********Source************\\n', input_from_user)\n",
    "# sortedSent = sorted(decoded_sentence_list, key=lambda kv: kv[1], reverse=True)\n",
    "# print('*********Decoded sentence with Beam Search***********\\n', sortedSent[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set BLEU score\n",
      "Start Index is:  0\n",
      "End Index is:  100000\n",
      "Input seq list length:  100000\n",
      "Translation length:  100000\n",
      "Predicted sentences length:  100000\n",
      "Source sentences length:  100000\n",
      "Actual sentences length:  100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lyceum/rr2n17/.conda/envs/rrkeras/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/lyceum/rr2n17/.conda/envs/rrkeras/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/lyceum/rr2n17/.conda/envs/rrkeras/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.359276\n",
      "BLEU-2: 0.401260\n",
      "BLEU-3: 0.371674\n",
      "BLEU-4: 0.329416\n"
     ]
    }
   ],
   "source": [
    "# #Training BLEU score\n",
    "# print ('Training set BLEU score')\n",
    "# evaluate_model(encoder_input_data_train, train, 0, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set BLEU score\n",
      "Start Index is:  100000\n",
      "End Index is:  148422\n",
      "Input seq list length:  48422\n",
      "Translation length:  48422\n",
      "Predicted sentences length:  48422\n",
      "Source sentences length:  48422\n",
      "Actual sentences length:  48422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lyceum/rr2n17/.conda/envs/rrkeras/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/lyceum/rr2n17/.conda/envs/rrkeras/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/lyceum/rr2n17/.conda/envs/rrkeras/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.367583\n",
      "BLEU-2: 0.369103\n",
      "BLEU-3: 0.336421\n",
      "BLEU-4: 0.297576\n"
     ]
    }
   ],
   "source": [
    "# #Test BLEU score\n",
    "# print ('Test set BLEU score')\n",
    "# evaluate_model(encoder_input_data_test, test, 100000, 148422, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predictions\n",
      "***************\n",
      "*********Source************\n",
      " ['लेकिन व्यवहार में ऐसा करना आसान नहीं है']\n",
      "*********Target************\n",
      " ['START_ but it is easier said than done _END']\n",
      "*********Decoded sentence***********\n",
      " [' but it is not easy to be able to do _END']\n"
     ]
    }
   ],
   "source": [
    "# offset = 110000\n",
    "# input_sent_list = list()\n",
    "# source_sent_list = list()\n",
    "# target_sent_list = list()\n",
    "# print('Starting predictions')\n",
    "# for seq_index in [110005]:\n",
    "#     input_sent = encoder_input_data_test[seq_index-offset : (seq_index-offset) + 1]\n",
    "#     input_sent_list.append(input_sent)\n",
    "#     target_sent_list.append(test.eng[seq_index])\n",
    "#     source_sent_list.append(test.hindi[seq_index])\n",
    "# decoded_sentence_list = decode_sequence(input_sent_list)\n",
    "\n",
    "# print('***************')\n",
    "# print('*********Source************\\n', source_sent_list)\n",
    "# print('*********Target************\\n', target_sent_list)\n",
    "# print('*********Decoded sentence***********\\n', decoded_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
